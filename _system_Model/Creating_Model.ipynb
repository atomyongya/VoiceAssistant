{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Keyword Spotting Model For Voice Assistant \"Numa\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(1) Importing Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Important Library\n",
    "import os\n",
    "import json\n",
    "from pprint import pprint\n",
    "import random\n",
    "import wave \n",
    "import struct\n",
    "\n",
    "# Audio Data Analysis Library\n",
    "import librosa\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Data Visualization Library\n",
    "import librosa.display\n",
    "import IPython.display as ipd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(2) Reading and Exploring Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mappings</th>\n",
       "      <th>labels</th>\n",
       "      <th>MFCCs</th>\n",
       "      <th>files</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>file</td>\n",
       "      <td>0</td>\n",
       "      <td>[[-757.322509765625, -2.326998710632324, -0.86...</td>\n",
       "      <td>/home/atomyongya/Documents/Herald/Final Year P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>open</td>\n",
       "      <td>0</td>\n",
       "      <td>[[-820.5107421875, 19.644493103027344, 4.52003...</td>\n",
       "      <td>/home/atomyongya/Documents/Herald/Final Year P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chrome</td>\n",
       "      <td>0</td>\n",
       "      <td>[[-768.443603515625, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>/home/atomyongya/Documents/Herald/Final Year P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>close</td>\n",
       "      <td>0</td>\n",
       "      <td>[[-855.1250610351562, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>/home/atomyongya/Documents/Herald/Final Year P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>folder</td>\n",
       "      <td>0</td>\n",
       "      <td>[[-978.7564697265625, -9.972305297851562, 8.94...</td>\n",
       "      <td>/home/atomyongya/Documents/Herald/Final Year P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>google</td>\n",
       "      <td>0</td>\n",
       "      <td>[[-829.8956298828125, 66.89012145996094, 66.90...</td>\n",
       "      <td>/home/atomyongya/Documents/Herald/Final Year P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>numa</td>\n",
       "      <td>0</td>\n",
       "      <td>[[-840.1062622070312, 6.9649152755737305, -38....</td>\n",
       "      <td>/home/atomyongya/Documents/Herald/Final Year P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>shutdown</td>\n",
       "      <td>0</td>\n",
       "      <td>[[-832.75146484375, 44.155982971191406, -14.18...</td>\n",
       "      <td>/home/atomyongya/Documents/Herald/Final Year P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>play</td>\n",
       "      <td>0</td>\n",
       "      <td>[[-871.768310546875, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>/home/atomyongya/Documents/Herald/Final Year P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>youtube</td>\n",
       "      <td>0</td>\n",
       "      <td>[[-773.2343139648438, 95.66471862792969, 11.54...</td>\n",
       "      <td>/home/atomyongya/Documents/Herald/Final Year P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>[[-892.963623046875, 12.419766426086426, 12.72...</td>\n",
       "      <td>/home/atomyongya/Documents/Herald/Final Year P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>[[-832.3006591796875, 9.610506057739258, -10.9...</td>\n",
       "      <td>/home/atomyongya/Documents/Herald/Final Year P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>[[-735.8442993164062, 42.96055603027344, -16.9...</td>\n",
       "      <td>/home/atomyongya/Documents/Herald/Final Year P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>[[-713.3851928710938, 53.6499137878418, -36.90...</td>\n",
       "      <td>/home/atomyongya/Documents/Herald/Final Year P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>[[-867.7271118164062, 10.697062492370605, 0.33...</td>\n",
       "      <td>/home/atomyongya/Documents/Herald/Final Year P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>[[-839.1319580078125, 8.022342681884766, 7.943...</td>\n",
       "      <td>/home/atomyongya/Documents/Herald/Final Year P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>[[-821.3856201171875, 41.513771057128906, -5.1...</td>\n",
       "      <td>/home/atomyongya/Documents/Herald/Final Year P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>[[-854.9798583984375, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>/home/atomyongya/Documents/Herald/Final Year P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>[[-818.2183227539062, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>/home/atomyongya/Documents/Herald/Final Year P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>[[-876.11083984375, 0.0, 0.0, 0.0, 0.0, 0.0, 0...</td>\n",
       "      <td>/home/atomyongya/Documents/Herald/Final Year P...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mappings labels                                              MFCCs  \\\n",
       "0       file      0  [[-757.322509765625, -2.326998710632324, -0.86...   \n",
       "1       open      0  [[-820.5107421875, 19.644493103027344, 4.52003...   \n",
       "2     chrome      0  [[-768.443603515625, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "3      close      0  [[-855.1250610351562, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "4     folder      0  [[-978.7564697265625, -9.972305297851562, 8.94...   \n",
       "5     google      0  [[-829.8956298828125, 66.89012145996094, 66.90...   \n",
       "6       numa      0  [[-840.1062622070312, 6.9649152755737305, -38....   \n",
       "7   shutdown      0  [[-832.75146484375, 44.155982971191406, -14.18...   \n",
       "8       play      0  [[-871.768310546875, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "9    youtube      0  [[-773.2343139648438, 95.66471862792969, 11.54...   \n",
       "10      None      0  [[-892.963623046875, 12.419766426086426, 12.72...   \n",
       "11      None      0  [[-832.3006591796875, 9.610506057739258, -10.9...   \n",
       "12      None      0  [[-735.8442993164062, 42.96055603027344, -16.9...   \n",
       "13      None      0  [[-713.3851928710938, 53.6499137878418, -36.90...   \n",
       "14      None      0  [[-867.7271118164062, 10.697062492370605, 0.33...   \n",
       "15      None      0  [[-839.1319580078125, 8.022342681884766, 7.943...   \n",
       "16      None      0  [[-821.3856201171875, 41.513771057128906, -5.1...   \n",
       "17      None      0  [[-854.9798583984375, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "18      None      0  [[-818.2183227539062, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "19      None      0  [[-876.11083984375, 0.0, 0.0, 0.0, 0.0, 0.0, 0...   \n",
       "\n",
       "                                                files  \n",
       "0   /home/atomyongya/Documents/Herald/Final Year P...  \n",
       "1   /home/atomyongya/Documents/Herald/Final Year P...  \n",
       "2   /home/atomyongya/Documents/Herald/Final Year P...  \n",
       "3   /home/atomyongya/Documents/Herald/Final Year P...  \n",
       "4   /home/atomyongya/Documents/Herald/Final Year P...  \n",
       "5   /home/atomyongya/Documents/Herald/Final Year P...  \n",
       "6   /home/atomyongya/Documents/Herald/Final Year P...  \n",
       "7   /home/atomyongya/Documents/Herald/Final Year P...  \n",
       "8   /home/atomyongya/Documents/Herald/Final Year P...  \n",
       "9   /home/atomyongya/Documents/Herald/Final Year P...  \n",
       "10  /home/atomyongya/Documents/Herald/Final Year P...  \n",
       "11  /home/atomyongya/Documents/Herald/Final Year P...  \n",
       "12  /home/atomyongya/Documents/Herald/Final Year P...  \n",
       "13  /home/atomyongya/Documents/Herald/Final Year P...  \n",
       "14  /home/atomyongya/Documents/Herald/Final Year P...  \n",
       "15  /home/atomyongya/Documents/Herald/Final Year P...  \n",
       "16  /home/atomyongya/Documents/Herald/Final Year P...  \n",
       "17  /home/atomyongya/Documents/Herald/Final Year P...  \n",
       "18  /home/atomyongya/Documents/Herald/Final Year P...  \n",
       "19  /home/atomyongya/Documents/Herald/Final Year P...  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Creating dataframe of json file.\n",
    "\n",
    ":param orginal_df (DataFrame) : Dataframe of json data. \n",
    ":param df : Copy file of orginal_df.\n",
    "\"\"\"\n",
    "\n",
    "json_Path_English = \"/home/atomyongya/Documents/Herald/Final Year Project/VoiceAssistant(Numa)/VoiceAssistant/_system_Model/2_English_KM/2_English_Json_Output_File/English_Data_JSON.json\"\n",
    "\n",
    "orginal_df = pd.read_json(json_Path_English, orient='index')\n",
    "df = orginal_df\n",
    "\n",
    "\"\"\"\n",
    "Applying transpose() function which changes the row elements into column \n",
    "elements and the column elements into row elements.\n",
    "\"\"\"\n",
    "\n",
    "df = df.transpose()\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mappings    917\n",
       "labels        0\n",
       "MFCCs         0\n",
       "files         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finding null value\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(927, 4)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shape of dataframe\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['file', 'open', 'chrome', 'close', 'folder', 'google', 'numa',\n",
       "       'shutdown', 'play', 'youtube', None], dtype=object)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unique class of \"mappings\" feature.\n",
    "mapping_Unique_Class = df[\"mappings\"].unique()\n",
    "mapping_Unique_Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=object)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unique class of \"labels\" feature\n",
    "labels_Unique_Class = df[\"labels\"].unique()\n",
    "labels_Unique_Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "927"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unique class of \"files\" feature\n",
    "files_Unique_Class = df[\"files\"].unique()\n",
    "len(files_Unique_Class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mappings</th>\n",
       "      <th>labels</th>\n",
       "      <th>MFCCs</th>\n",
       "      <th>files</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10</td>\n",
       "      <td>927</td>\n",
       "      <td>927</td>\n",
       "      <td>927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>869</td>\n",
       "      <td>927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>file</td>\n",
       "      <td>2</td>\n",
       "      <td>[[-666.6397705078125, 73.39788818359375, 11.13...</td>\n",
       "      <td>/home/atomyongya/Documents/Herald/Final Year P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       mappings  labels                                              MFCCs  \\\n",
       "count        10     927                                                927   \n",
       "unique       10      10                                                869   \n",
       "top        file       2  [[-666.6397705078125, 73.39788818359375, 11.13...   \n",
       "freq          1     100                                                  2   \n",
       "\n",
       "                                                    files  \n",
       "count                                                 927  \n",
       "unique                                                927  \n",
       "top     /home/atomyongya/Documents/Herald/Final Year P...  \n",
       "freq                                                    1  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 927 entries, 0 to 926\n",
      "Data columns (total 4 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   mappings  10 non-null     object\n",
      " 1   labels    927 non-null    object\n",
      " 2   MFCCs     927 non-null    object\n",
      " 3   files     927 non-null    object\n",
      "dtypes: object(4)\n",
      "memory usage: 29.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(3) Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Lode json file.\n",
    "\n",
    ":param data (dict) : Dictonary which store the JSON data. \n",
    "\"\"\"\n",
    "\n",
    "with open(json_Path_English) as json_Data:\n",
    "    data = json.load(json_Data)\n",
    "\n",
    "# pprint(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyzing audio data before preparing dataset to get more information of our audio data.\n",
    "\n",
    "class Meta_Data():\n",
    "    \"\"\"\n",
    "    The information from class \"Meta_Data\" will be used later to create a model.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, audio_Data_Path):\n",
    "        \"\"\"\n",
    "        :param audio_Data_Path : path of audio data.\n",
    "        \"\"\"\n",
    "        \n",
    "        self.path = audio_Data_Path\n",
    "    \n",
    "    # Method to play audio\n",
    "    def play_Audio(self):\n",
    "        \"\"\"\n",
    "        Playing Audio to make sure we are using the correct input to extract MFCCs.\n",
    "        \n",
    "        :param audio : audio file in .wav format.\n",
    "        \"\"\"\n",
    "        \n",
    "        audio = ipd.Audio(self.path)\n",
    "        \n",
    "        return audio\n",
    "    \n",
    "    # Method to Extract MFCCs\n",
    "    def extracting_MFCCs(self):\n",
    "        \"\"\"\n",
    "        MFCCs (Mel Frequency Cepstrum Coefficent) is representation of the short-term power spectrum of an audio or sound.\n",
    "        \n",
    "        :param signal : \n",
    "        :param sample_Rate : Number of sample in one second.\n",
    "        :param n_mfcc : Number of coefficent (y-intercept).\n",
    "        :paramm mfccs: Feature of audio data in 2D array.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Loading audio files\n",
    "        signal, sample_Rate = librosa.load(self.path)\n",
    "        \n",
    "        # Extracting MFCCs Feature\n",
    "        mfccs = librosa.feature.mfcc(y=signal, n_mfcc=13, sr=sample_Rate)\n",
    "        print(\"Shape of an audio: \", mfccs.shape)\n",
    "        \n",
    "        return signal, sample_Rate, mfccs\n",
    "    \n",
    "    # Method to Visualise MFCCs in json\n",
    "    def visualising_MFCCs(self):\n",
    "        signal, sample_Rate, mfccs = self.extracting_MFCCs()\n",
    "        plt.figure(figsize=(25, 10))\n",
    "        librosa.display.specshow(mfccs, x_axis=\"time\", sr=sample_Rate)\n",
    "        plt.title(\"Mel Frequency Cepstrum Coefficent (MFCCs)\")\n",
    "        plt.colorbar(format=\"%+2.f\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating class for data visualization from dataframe\n",
    "class Graph_Plot():\n",
    "    \n",
    "    \"\"\"\n",
    "    :param x_Axis : input feature\n",
    "    :param y_Axis : output\n",
    "    \n",
    "    \"\"\"\n",
    "    def it__(self, x_Axis, y_Axis):\n",
    "        self.x_Axis = x_Axis\n",
    "        self.y_Axis = y_Axis\n",
    "\n",
    "    def figure_Size(self): \n",
    "        figure_Size = plt.figure(figsize=(15, 7))\n",
    "\n",
    "    def bar_Plot(self):\n",
    "        self.figure_Size()\n",
    "        sns.barplot(x=self.x_Axis, y=self.y_Axis, data=df)\n",
    "\n",
    "    def box_Plot(self):\n",
    "        self.figure_Size()\n",
    "        plt.boxplot(x=self.x_Axis, data=df)\n",
    "        plt.show()\n",
    "\n",
    "    def swarmp_Plot(self):\n",
    "        self.figure_Size()\n",
    "        sns.swarmplot(x=self.x_Axis, y=self.y_Axis, data=df)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Creating first object of class Meta_Data randomly\n",
    "# audio_Path = random.choice(data[\"files\"])\n",
    "# random_Audio_Object = Meta_Data(audio_Path)\n",
    "\n",
    "# # Calling play_Audio() method from class Meta_Data for first object\n",
    "# random_Audio_Object.play_Audio()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"\n",
    "# :param name_Of_File : Split the directory and store in list. [-2] Return the second last index value.\n",
    "# \"\"\"\n",
    "# name_of_File = audio_Path.split(\"/\")[-2]\n",
    "# print(name_of_File + \" Audio\\n\")\n",
    "\n",
    "# random_Audio_Object.visualising_MFCCs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Creating second object of Meta_Data \n",
    "# audio_Path2 = random.choice(data[\"files\"])\n",
    "# random_Audio_Object2 = Meta_Data(audio_Path2)\n",
    "\n",
    "# # Calling play_Audio() method from class Meta_Data for first object\n",
    "# random_Audio_Object2.play_Audio()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_Path_Name = audio_Path2.split(\"/\")[-2]\n",
    "# print(file_Path_Name + \" Audio\\n\")\n",
    "# random_Audio_Object2.visualising_MFCCs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mfccs = df[\"MFCCs\"]\n",
    "# mapping = df[\"mappings\"]\n",
    "# labels = df[\"labels\"]\n",
    "\n",
    "# mfccs.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapping.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(4) Creating Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Library to create model\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Creating keyword spotting model for speech recognition system.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "class Create_Model():\n",
    "    \"\"\"\n",
    "    Class to create model.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, data_Path, save_Model_Path, batch_size, epochs, learning_Rate):\n",
    "        \"\"\"\n",
    "        Constructor function.\n",
    "        \n",
    "        :param data_Path : Path of the JSON file.\n",
    "        :param save_Model : Path where .h5 model will be saved.\n",
    "        :param batch_size : Number of sample processed before the model is updated.\n",
    "        :param epochs : one entire transit of the training data through the algorithm.\n",
    "        :param learning_Rate : Hyperparameter of lstm algorithm which decide how training process data will be selected \n",
    "                                due to which the building model can take long or short period of time.\n",
    "        \"\"\"\n",
    "        \n",
    "        self.data_Path = data_Path\n",
    "        self.save_Model_Path = save_Model_Path\n",
    "        self.batch_size = batch_size\n",
    "        self.epochs = epochs\n",
    "        self.learning_Rate = learning_Rate\n",
    "    \n",
    "    def load_Dataset(self, data_Path):\n",
    "        \"\"\"\n",
    "        Loading JSON dataset.\n",
    "        \n",
    "        :var data : Dictionary to store json data after loading.\n",
    "        :var X : Input feature.\n",
    "        :var y : Output.\n",
    "        \"\"\"\n",
    "        # Loading JSON File\n",
    "        with open(data_Path, \"r\") as json_Data:\n",
    "            data = json.load(json_Data)\n",
    "            \n",
    "        # Extract Inputs and Targets (or Labels) Features\n",
    "        X = np.asarray(data[\"MFCCs\"], dtype=object)\n",
    "        y = np.asarray(data[\"labels\"], dtype=object)\n",
    "        \n",
    "        return X, y\n",
    "    \n",
    "    def get_Data_Splits(self, data_Path, test_size=0.1, test_validation=0.1):\n",
    "        \"\"\"\n",
    "        Splitting the data in train, test, validation.\n",
    "        \n",
    "        :param test_size : Size of test data from whole dataset.\n",
    "        :param test_validation : Size of validation data from remaining tranning dataset.\n",
    "        \n",
    "        :var X_train : Input training data for model.\n",
    "        :var X_test : Input testing data for model.\n",
    "        :var X_validation : Input Validation data for model.\n",
    "        \n",
    "        :var y_train : Output training data for model.\n",
    "        :var y_test : Output testing data for model. \n",
    "        :var y_validation : Output validation data for model.\n",
    "        \"\"\"\n",
    "        # Load Dataset\n",
    "        X, y = self.load_Dataset(self.data_Path)\n",
    "        \n",
    "        # split train/Validation/test \n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size)\n",
    "        X_train, X_validation, y_train, y_validation = train_test_split(X_train, y_train, test_size=test_validation)\n",
    "        \n",
    "        X_train = tf.convert_to_tensor(X_train, dtype=tf.float32) \n",
    "        X_validation = tf.convert_to_tensor(X_validation, dtype=tf.float32)\n",
    "        X_test = tf.convert_to_tensor(X_test, dtype=tf.float32)\n",
    "        y_train = tf.convert_to_tensor(y_train, dtype=tf.float32) \n",
    "        y_validation = tf.convert_to_tensor(y_validation, dtype=tf.float32)\n",
    "        y_test = tf.convert_to_tensor(y_test, dtype=tf.float32)\n",
    "        \n",
    "        return X_train, X_validation, X_test, y_train, y_validation, y_test \n",
    "    \n",
    "    def build_Model(self, input_shape, learning_Rate, error=\"sparse_categorical_crossentropy\", number_Keywords=10):\n",
    "        \"\"\"\n",
    "        Building the keyspotting model.\n",
    "        \n",
    "        :param error : Algorithm to calculate the error of model.\n",
    "        :param number_Keywords : Number of word we collected for traning purpose.\n",
    "        \n",
    "        :var model : Model type.\n",
    "        :var optimiser : Algorithm that helps to reduce loss or error and increase the accuracy of model.\n",
    "        \"\"\"\n",
    "        # Build network\n",
    "        model = keras.Sequential()\n",
    "        \n",
    "        # 2 LSTM Layer\n",
    "        model.add(keras.layers.LSTM(64, input_shape=input_shape, return_sequences=True))\n",
    "        model.add(keras.layers.LSTM(64))\n",
    "        \n",
    "        # Dense Layer\n",
    "        model.add(keras.layers.Dense(64, activation=\"relu\"))\n",
    "        model.add(keras.layers.Dropout(0.3))\n",
    "        \n",
    "        # Softmax classifier (or Output layer)\n",
    "        model.add(keras.layers.Dense(number_Keywords, activation=\"softmax\")) # [0.1, 0.7, 0.2] 0.7 will be output\n",
    "        \n",
    "        # Compile the model\n",
    "        optimiser = keras.optimizers.Adam(learning_rate=self.learning_Rate)\n",
    "        model.compile(optimizer=optimiser, loss=error, metrics=[\"accuracy\"])\n",
    "        \n",
    "        # Print model overview\n",
    "        model.summary()\n",
    "        \n",
    "        return model\n",
    "        \n",
    "    def main(self):\n",
    "        \"\"\"\n",
    "        Main function from where the process of creating model start.\n",
    "        \n",
    "        :var input_shape : input shape of the first node in neural network.\n",
    "        :var test_error : Error of our model.\n",
    "        :var test_accuracy : Accuracy of our model.\n",
    "        \"\"\"\n",
    "        # train /  validation / test data splits\n",
    "        X_train, X_validation, X_test, y_train, y_validation, y_test = self.get_Data_Splits(self.data_Path)\n",
    "        \n",
    "        # Building LSTM Model\n",
    "        input_shape = (X_train.shape[1], X_train.shape[2])\n",
    "        model = self.build_Model(input_shape, self.learning_Rate)\n",
    "        \n",
    "        # Train the data using model\n",
    "        model.fit(X_train, y_train, epochs=self.epochs, batch_size=self.batch_size, validation_data=(X_validation, y_validation))\n",
    "        \n",
    "        # Evaluating the model\n",
    "        test_error, test_accuracy = model.evaluate(X_test, y_test)\n",
    "        print(f\"Test error: {test_error}, Test accuracy: {test_accuracy}\")\n",
    "        \n",
    "        # Saving model\n",
    "        model.save(self.save_Model_Path)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"\n",
    "# Creating object of class Create_Model for English language.\n",
    "\n",
    "# :var json_Path_English : Path of JSON dataset for English language.\n",
    "# :var english_Model_Path : Path where english keyspotting model get saved. \n",
    "# \"\"\"\n",
    "\n",
    "# learning_Rate = 0.0001\n",
    "# epochs = 100\n",
    "# batch_size = 32\n",
    "\n",
    "# # Data Path\n",
    "# json_Path_English = \"/home/atomyongya/Documents/Herald/Final Year Project/VoiceAssistant(Numa)/VoiceAssistant/1 System Model/2_English_KM/2_English_Json_Output_File/English_Data_JSON.json\"\n",
    "\n",
    "# # Model Path\n",
    "# english_Model_Path = \"/home/atomyongya/Documents/Herald/Final Year Project/VoiceAssistant(Numa)/VoiceAssistant/1 System Model/2_English_KM/3_English_Model_File/english_Model.h5\"\n",
    "\n",
    "# # Creating model object for English\n",
    "# english_Model_Object = Create_Model(json_Path_English, english_Model_Path, batch_size, epochs, learning_Rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nCreating object of class create_Model for Nepali Language.\\n'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Creating object of class create_Model for Nepali Language.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calling main function of object english_Model_Object\n",
    "# english_Model_Object.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calling main function of object nepali_Model_Object\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making Prediction Using our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Importing Library necessary to predict our model\n",
    "\"\"\"\n",
    "import sounddevice as sd\n",
    "import scipy.io.wavfile as sw\n",
    "from scipy.io.wavfile import write\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "from scipy import fftpack\n",
    "import noisereduce as nr\n",
    "import soundfile as sf\n",
    "import io\n",
    "import subprocess\n",
    "import wavefile\n",
    "\n",
    "from scipy.io import wavfile as wav\n",
    "from scipy.io.wavfile import write\n",
    "import sounddevice as sd\n",
    "from playsound import playsound\n",
    "import noisereduce as nr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction Started: \n",
      "Say Now: \n",
      "numa\n",
      "Enter S or s to stop: \n",
      "Say Now: \n",
      "shutdown\n",
      "Enter S or s to stop: \n",
      "Say Now: \n",
      "shutdown\n",
      "Enter S or s to stop: \n",
      "Say Now: \n",
      "numa\n",
      "Enter S or s to stop: \n",
      "Say Now: \n",
      "google\n",
      "Enter S or s to stop: \n",
      "Say Now: \n",
      "open\n",
      "Enter S or s to stop: \n",
      "Say Now: \n",
      "google\n",
      "Enter S or s to stop: \n",
      "Say Now: \n",
      "shutdown\n",
      "Enter S or s to stop: \n",
      "Say Now: \n",
      "close\n",
      "Enter S or s to stop: \n",
      "Say Now: \n",
      "numa\n",
      "Enter S or s to stop: \n",
      "Say Now: \n",
      "close\n",
      "Enter S or s to stop: \n",
      "Say Now: \n",
      "shutdown\n",
      "Enter S or s to stop: \n",
      "Say Now: \n",
      "close\n",
      "Enter S or s to stop: \n",
      "Say Now: \n",
      "numa\n",
      "Enter S or s to stop: \n",
      "Say Now: \n",
      "shutdown\n",
      "Enter S or s to stop: s\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Making prediction using english model we create.\n",
    "\n",
    ":param fps: frame per second.\n",
    ":param duaration : Record time duration.\n",
    ":param filename : audio path.\n",
    ":param mapping_Data : Loding the data to compare with our real time audio.\n",
    "\"\"\"\n",
    "\n",
    "fps = 44100\n",
    "duration = 1\n",
    "filename = \"prediction.wav\"\n",
    "mapping_Data = data[\"mappings\"]\n",
    "\n",
    "# English keyword spotting model\n",
    "model = load_model(\"/home/atomyongya/Documents/Herald/Final Year Project/VoiceAssistant(Numa)/VoiceAssistant/_system_Model/2_English_KM/3_English_Model_File/english_Model.h5\")\n",
    "\n",
    "print(\"Prediction Started: \")\n",
    "while True:\n",
    "    \n",
    "    \"\"\"\n",
    "    :param myrecording :  Audio to predict real time user voice.\n",
    "    :param prediction :  Prediction of real time audio voice.\n",
    "    :param predicted_index : Hold the max prediction value of our model.\n",
    "    :param predicted_keyword : Text word with which our voice will get compared. \n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Real time audio recording.  \n",
    "        print(\"Say Now: \")\n",
    "        myrecording = sd.rec(int(duration * fps), samplerate=fps, channels=2)\n",
    "        sd.wait()\n",
    "        write(filename, fps, myrecording)\n",
    "        \n",
    "        # Removing noise.\n",
    "        rate, reduced_data = sw.read('prediction.wav') \n",
    "        noise_Reduce = nr.reduce_noise(np.reshape(reduced_data, (2, -1)), rate)\n",
    "        \n",
    "        write(\"noise_Reduce.wav\", fps, reduced_data)\n",
    "        \n",
    "        # Loading the recorded file using librosa.\n",
    "        signal, sample_rate = librosa.load('prediction.wav')\n",
    "        \n",
    "        # Extracting the MFCC feature of an audio\n",
    "        mfcc = librosa.feature.mfcc(signal, sample_rate, n_mfcc=13, hop_length=512, n_fft=2048)\n",
    "        \n",
    "        # Making prediction and comparing our audio mfcc with the mfcc of train audio data\n",
    "        prediction = model.predict(tf.expand_dims(mfcc.T, axis=0))\n",
    "        \n",
    "        # Finding max prediction value and mapping with the index of mapping_Data from json. \n",
    "        predicted_index = np.argmax(prediction)\n",
    "        predicted_keyword = mapping_Data[predicted_index]\n",
    "        print(predicted_keyword)\n",
    "        \n",
    "        # To stop the audio record.\n",
    "        stop = input(\"Enter S or s to stop: \")\n",
    "        if stop == \"s\" or stop == \"S\":\n",
    "            break\n",
    "\n",
    "        else:\n",
    "            continue\n",
    "            \n",
    "    except Exception as error:\n",
    "        print(error)\n",
    "        break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Say Now: \n"
     ]
    }
   ],
   "source": [
    "from scipy.io import wavfile as wav\n",
    "from scipy.io.wavfile import write\n",
    "import sounddevice as sd\n",
    "from playsound import playsound\n",
    "import noisereduce as nr\n",
    "\n",
    "fs = 44100  # Sample rate\n",
    "seconds = 2   # Duration of recording\n",
    "print(\"Say Now: \")\n",
    "myrecording = sd.rec(int(seconds * fs), samplerate=fs, channels=2)\n",
    "sd.wait()  # Wait until recording is finished\n",
    "write('prediction.wav', fs, myrecording)\n",
    "\n",
    "rate, data = sw.read('prediction.wav') \n",
    "reduced_noise = nr.reduce_noise(np.reshape(data, (2, -1)), rate)\n",
    "\n",
    "write(\"reduced_noise.wav\", fs, data)\n",
    "playsound(\"reduced_noise.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import torch \n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# orginal_df = pd.read_json(\"/home/atomyongya/Documents/Herald/Final Year Project/VoiceAssistant(Numa)/VoiceAssistant/Numa_Backend_Code/Model/Acoustic_Model/English_AM/json_Folder/english.json\")\n",
    "# df = orginal_df\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"/home/atomyongya/Documents/Herald/Final Year Project/VoiceAssistant(Numa)/VoiceAssistant/Numa_Backend_Code/Model/Acoustic_Model/English_AM/json_Folder/english.json\"\n",
    "model_path = \"/home/atomyongya/Documents/Herald/Final Year Project/VoiceAssistant(Numa)/VoiceAssistant/Numa_Backend_Code/Model/Acoustic_Model/English_AM/model_Folder\"\n",
    "learning_rate = 0.0001\n",
    "Epochs = 100\n",
    "batchSize = 32\n",
    "num_keyword = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(data_path):\n",
    "    with open(data_path, \"r\") as fp:\n",
    "        data = json.load(fp)\n",
    "        # print(data)\n",
    "    # eextract inputs and targets\n",
    "    X = np.array(data[\"MFCCs\"], dtype=object)\n",
    "    y = np.array(data[\"labels\"], dtype=object)\n",
    "    # print(X)\n",
    "    \n",
    "    # X = torch.from_numpy(data[\"MFCCs\"])\n",
    "    # y = torch.from_numpy(data[\"labels\"])\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_split(data_path, test_size=0.1, test_validation=0.1):\n",
    "    # load the dataset\n",
    "    X, y = load_dataset(data_path)\n",
    "    \n",
    "    # create train/validation/test splits\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size)\n",
    "    X_train, X_validation, y_train, y_validation = train_test_split(X_train, y_train, test_size=test_validation)\n",
    "    \n",
    "    # convert inputs from 3d to 3d arrays\n",
    "    X_train = X_train[..., np.newaxis]     \n",
    "    X_validation = X_validation[..., np.newaxis]     \n",
    "    X_test = X_test[..., np.newaxis]     \n",
    "    \n",
    "    return X_train, X_validation, X_test, y_train, y_validation, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the model\n",
    "def build_model(input_shapes, learning_rate, error=\"sparse_categorical_crossentropy\"):\n",
    "    # bild network\n",
    "    model = keras.Sequential()\n",
    "    \n",
    "    # RNN layer 1\n",
    "    model.add(keras.layers.Conv2D(64, (3, 3), activation=\"relu\", input_shape=input_shapes, kernel_regularizer=keras.regularizers.l2(0.001), padding=\"same\"))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.MaxPool2D((3, 3), strides=(2, 2), padding=\"same\"))\n",
    "    \n",
    "    # RNN layer 2\n",
    "    model.add(keras.layers.Conv2D(32, (3, 3), activation=\"relu\", kernel_regularizer=keras.regularizers.l2(0.001), padding=\"same\"))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.MaxPool2D((3, 3), strides=(2, 2), padding=\"same\"))\n",
    "    \n",
    "    # RNN layer 3\n",
    "    model.add(keras.layers.Conv2D(32, (2, 2), activation=\"relu\", kernel_regularizer=keras.regularizers.l2(0.001), padding=\"same\"))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.MaxPool2D((2, 2), strides=(2, 2), padding=\"same\"))\n",
    "    \n",
    "    # flatten the output feed it into a dense layer \n",
    "    model.add(keras.layers.Flatten())\n",
    "    model.add(keras.layers.Dense(64, activation=\"relu\"))\n",
    "    model.add(keras.layers.Dropout(0.3))\n",
    "    \n",
    "    # softmax classifier (output layer)\n",
    "    model.add(keras.layers.Dense(num_keyword, activation=\"softmax\"))\n",
    "    \n",
    "    # Compile the model\n",
    "    optimiser = keras.optimizers.Adam(learning_rate)\n",
    "    model.compile(optimizer=optimiser, loss=error, metrics=[\"accuracy\"])\n",
    "    \n",
    "    # print model overview\n",
    "    model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # load train/Validation/test data splits\n",
    "    X_train, X_validation, X_test, y_train, y_validation, y_test = get_data_split(data_path)\n",
    "    \n",
    "    # Build the RNN LSTM Model\n",
    "     # X_train first = ndarray, X_train second = coeffiecent 13, X_train third = Channel or depth 1\n",
    "    input_shape = (X_train.shape[1], X_train.shape[2], 1)\n",
    "    model = build_model(input_shape, learning_rate)\n",
    "    \n",
    "    # train the model\n",
    "    model.fit(X_train, y_train, epochs=Epochs, batch_size=batchSize, validation_data=(X_validation, y_validation))\n",
    "    \n",
    "    # Evaluate the model\n",
    "    test_error, test_accuracy = model.evaluate(X_test, y_test)\n",
    "    print(f\"Test error: {test_error}, test_accuracy: {test_accuracy}\")\n",
    "    \n",
    "    # save the model\n",
    "    model.save(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-c7bc734e5e35>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-18-b2d6af15103f>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# Build the RNN LSTM Model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m      \u001b[0;31m# X_train first = ndarray, X_train second = coeffiecent 13, X_train third = Channel or depth 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
